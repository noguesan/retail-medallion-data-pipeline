# ðŸ“˜ dbt & Databricks â€” GuÃ­a de EjecuciÃ³n e InterpretaciÃ³n del Proyecto

## 1. Objetivo del documento

Este documento explica **cÃ³mo ejecutar** y **cÃ³mo interpretar** el proyecto `retail-medallion-data-pipeline`, con foco en el uso combinado de **Databricks** y **dbt** bajo una **arquitectura Medallion (Bronze / Silver / Gold)**.

EstÃ¡ pensado para:

* Personas que clonan el repositorio y quieren correrlo
* Entrevistadores tÃ©cnicos
* Data Engineers / Analytics Engineers que quieran entender el modelo

No explica el paso a paso de construcciÃ³n (eso vive en `docs/Guia_Construccion de proyecto`).

---

## 2. Arquitectura general del proyecto

El pipeline sigue una arquitectura **Medallion**, separando responsabilidades:

### ðŸŸ« Bronze (ingestiÃ³n cruda)

* Datos tal como llegan de la fuente
* Transformaciones mÃ­nimas o inexistentes
* Se manejan principalmente en **Databricks**

### ðŸª™ Silver (datos limpios y normalizados)

* Tipos corregidos
* Duplicados tratados
* Reglas de calidad bÃ¡sicas
* Estas tablas se crean en **Databricks** y se exponen como *sources* para dbt

### ðŸ¥‡ Gold (datos analÃ­ticos)

* Modelos listos para negocio
* Dimensiones y tablas de hechos
* Tests de calidad y relaciones
* Construidos y documentados con **dbt**

---

## 3. Â¿QuÃ© ver y hacer en Databricks?

Databricks se utiliza como **motor de procesamiento y almacenamiento**.

### En Databricks se debe:

* Ejecutar notebooks de ingestiÃ³n (Bronze)
* Crear y mantener las tablas **Silver**
* Consultar datos con SQL para validaciones rÃ¡pidas

Ejemplo de consulta:

```sql
SELECT *
FROM retail_medallion_pipeline_schema.silver_orders
LIMIT 10;
```

Databricks **no contiene la lÃ³gica analÃ­tica final**: esa vive en dbt.

---

## 4. Â¿QuÃ© ver y hacer en dbt?

dbt se usa para:

* Modelar la capa **Gold**
* Definir dependencias entre modelos
* Ejecutar tests de calidad
* Generar documentaciÃ³n y lineage

### 4.1 Estructura del proyecto dbt

```text
models/
â”œâ”€â”€ staging/
â”‚   â”œâ”€â”€ stg_customers.sql
â”‚   â”œâ”€â”€ stg_orders.sql
â”‚   â””â”€â”€ stg_products.sql
â””â”€â”€ marts/
    â”œâ”€â”€ dimensions/
    â”‚   â”œâ”€â”€ dim_customers.sql
    â”‚   â””â”€â”€ dim_products.sql
    â””â”€â”€ facts/
        â””â”€â”€ fact_orders.sql
```

---

## 5. ExplicaciÃ³n de los modelos

### ðŸ”¹ Staging models (`stg_*`)

**Objetivo:** adaptar las tablas Silver al estÃ¡ndar dbt.

* Renombre de columnas
* Tipos consistentes
* Nombres claros

No agregan lÃ³gica de negocio.

---

### ðŸ”¹ Dimensiones (`dim_*`)

#### `dim_customers`

Representa a los clientes.

* 1 fila por cliente
* Usada para anÃ¡lisis por paÃ­s, cliente, cohortes

#### `dim_products`

Representa los productos.

* 1 fila por producto
* Permite anÃ¡lisis por categorÃ­a y precio

---

### ðŸ”¹ Tabla de hechos (`fact_orders`)

Modelo central del anÃ¡lisis.

Contiene:

* MÃ©tricas (quantity, total_amount)
* Claves hacia dimensiones

Permite responder preguntas como:

* Ventas por cliente
* Ventas por producto
* Volumen y revenue

---

## 6. Tests de calidad en dbt

dbt permite definir tests declarativos.

### Tipos usados en este proyecto:

#### âœ” `not_null`

Asegura que un campo obligatorio no tenga nulos.

#### âœ” `unique`

Asegura unicidad (ej: claves primarias).

#### âœ” `relationships`

Verifica **integridad referencial**.

Ejemplo:

> Cada `customer_id` en `fact_orders` debe existir en `dim_customers`.

Si falla:

* Hay datos huÃ©rfanos
* El modelo no es confiable

---

## 7. CÃ³mo ejecutar el proyecto dbt

Desde:

```text
dbt/retail_medallion_gold/
```

### Ejecutar modelos

```bash
py -m dbt.cli.main run
```

### Ejecutar tests

```bash
py -m dbt.cli.main test
```

---

## 8. DocumentaciÃ³n dbt (muy importante)

dbt genera documentaciÃ³n navegable.

### Generar docs

```bash
py -m dbt.cli.main docs generate
```

### Servir docs localmente

```bash
py -m dbt.cli.main docs serve
```

Abrir en el navegador:

```
http://localhost:8080
```

---

## 9. CÃ³mo interpretar dbt Docs

### Secciones clave:

#### ðŸ“Œ Lineage

* Ver dependencias entre modelos
* Entender el flujo Silver â†’ Staging â†’ Gold

#### ðŸ“Œ Models

* DescripciÃ³n de cada tabla
* Columnas y tests asociados

#### ðŸ“Œ Tests

* Estado de calidad de los datos

Esta documentaciÃ³n es **clave para analytics y negocio**.

---

## 10. Resumen conceptual

| Herramienta | Rol                               |
| ----------- | --------------------------------- |
| Databricks  | Procesamiento y almacenamiento    |
| dbt         | Modelado, calidad y documentaciÃ³n |
| Silver      | Datos limpios                     |
| Gold        | Datos analÃ­ticos                  |

Este enfoque separa responsabilidades y escala correctamente.

---

## 11. PrÃ³ximos pasos posibles

* Incremental models
* Snapshots
* Exposures
* OrquestaciÃ³n (Jobs / Airflow)

---

ðŸ“Œ *Este proyecto demuestra un pipeline moderno de Data Engineering con foco en calidad y mantenibilidad.*
